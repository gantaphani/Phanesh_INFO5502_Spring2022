{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJn2JV6XZ0Mi"
      },
      "source": [
        "## The third Lab-assignment (02/10/2022, 50 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lVijdOvZ0Mk"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1_qDxneZ0Ml"
      },
      "source": [
        "Question 1 (10 points). Fomulate your domain problem: Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy0vmfSvZ0Ml"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "I would like to predict whether the movie is good or bad.\n",
        "To achieve this, I want to gather reviews from different users on various websites and estimate the polarity of the review, i.e., positive or negative or neutral.\n",
        "\n",
        "Because if there is a direct rating score, you can take a mean value and decide, whereas if you only have text reviews,  you'll have to give a score based on the review.\n",
        "Furthermore, while determining whether a product is good or bad, the data collected should be free of bias.\n",
        "Also, the review we're gathering should be from a verified consumer or purchase to get better results.\n",
        "\n",
        "Before I can begin analyzing this data, I need to do some data mining, such as deleting unnecessary, empty reviews, comments about other products,\n",
        "reviews written by a same person, and so on.\n",
        "\n",
        "As the amount of data grows, the amount of effort and cost increases, and also collecting unnecessary data may result in inaccurate results.\n",
        "\n",
        "The above we are doing is sentiment analysis. We don't have any criteria for how much information should be gathered.\n",
        "It is dependent on a number of things, including data availability.\n",
        "\n",
        "However, we must ensure that the data is suitable for analysis because much information is removed during text preprocessing,\n",
        "such as numbers, punctuation, special characters, and foreign languages.\n",
        "\n",
        "The ideal way to acquire data is to obtain copyrights of the website, and there are a variety of web scraping tools available, such as ParseHub, Scrapy, and others.\n",
        "\n",
        "I imported 1000 reviews from imdb for the movie Joker into a Data frame using the pandas and selenium packages,\n",
        "then eliminated duplicates and missing information to increase accuracy.\n",
        "\n",
        "The collected data can be saved in csv, excel, or txt format for analysis.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud1ge6irZ0Mm"
      },
      "source": [
        "Question 2 (10 points). Collect your data to answer the research problem: Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPw-4fShZ0Mm"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!apt-get update #Updating the list of existing packages to keep it up to date\n",
        "#Installing Selenium and the Google Chrome Web Driver\n",
        "!pip install selenium\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_experimental_option('prefs', {'intl.accept_languages': 'en,en_US'})\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "wb = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ],
      "metadata": {
        "id": "G5Vl3CeJ9yqI"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "\n",
        "link = 'https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv'\n",
        "titleArray = [] \n",
        "reviewArray = []\n",
        "wb.get(link)\n",
        "\n",
        "for num in range(40): #Giving range to get 1000 reviews\n",
        "  wb.find_element_by_class_name(\"ipl-load-more__button\").click() #Clicking Load More Button\n",
        "  time.sleep(5)\n",
        "  titles = wb.find_elements(By.CLASS_NAME, \"title\")#Extracting titles from page by filtering with the class 'title'\n",
        "  reviews = wb.find_elements(By.CLASS_NAME, \"text\")#Extracting reviews from page by filtering with the class 'text'\n",
        "\n",
        "for title,review in zip(titles,reviews):\n",
        "      titleArray.append(title.text)\n",
        "      reviewArray.append((review.text).replace('\\n',''))\n",
        "\n",
        "result = pd.DataFrame(list(zip(title_array, review_array)), columns =['Title', 'Review'])\n",
        "\n",
        "result.drop_duplicates(inplace=True) #removing NULL values from the dataframe\n",
        "result.dropNa(inplace=True) #removing duplicate records from the dataframe\n",
        "result.reset_index(inplace=True,drop=True) #Resetting the index values for the data frame\n",
        "\n",
        "print(\"Length of the Dataset:\",len(result))\n",
        "print(result.head(10))\n",
        "\n",
        "result.to_csv('Reviews.csv',sep=',') #writing dataset to csv"
      ],
      "metadata": {
        "id": "MEzPreqDNe7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iCHmrowZ0Mm"
      },
      "source": [
        "Question 3 (10 points). Understand the data quality: Search a second hand dataset (any dataset) from kaggle or other websites. Describe the data quality problem of the dataset and explain your strtegy to clean the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyf3mQAkZ0Mn"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "'''\n",
        "Dataset Name: Amazon Fine Food Reviews\n",
        "Source: https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
        "Overview: This dataset consists of reviews of fine foods from amazon for the span of 13 yrs(OCT 1999 - OCT 2012).\n",
        "\n",
        "Number of reviews: 568454\n",
        "Number of users: 256059\n",
        "Number of products: 74258\n",
        "Number of Attributes: 10\n",
        "\n",
        "Attribute Information:\n",
        "Id\n",
        "ProductId - Unique Identifier for the product\n",
        "UserId - Unique Identifier for the user\n",
        "ProfileName\n",
        "Helpfulness Numerator - Number of Users who found the review is helpful\n",
        "Helpfulness Denominator - Number of Users who indicated whether the review is helpful or not\n",
        "Score - rating between 1 and 5\n",
        "Time - Time stamp for the review\n",
        "Summary - Brief summary of the review\n",
        "Text - Text of the review\n",
        "\n",
        "Many duplicate entries were found in this data set (reviews data).Duplicate items must be removed in order to obtain unbiased findings for data analysis.\n",
        "\n",
        "For example, the user Geeta Krishna has three reviews for the same product with the same Helpfulness numerator, Helpfulness denominator, Score, Summary, and Text in this dataset.\n",
        "The intriguing thing is that they are supplied at the exact time stamp without milliseconds difference, which is impossible to achieve in real time.\n",
        "As a result, deduplication is required because including these three evaluations adds no value to the analysis.\n",
        "\n",
        "Furthermore, for some of the reviews, the Helpful Numerator is greater than the Helpful Denominator, which is not technically valid.\n",
        "Because the Helpful numerator counts the number of people who said yes, whereas the Helpful denominator counts the number of people who said yes and no.\n",
        "Therefore, this form of semantically invalid data must be eliminated.\n",
        "\n",
        "When you're data cleaning, removing unwanted columns from the data set will free up space and speed up the run time.\n",
        "This dataset is used to determine if a food item is good or poor. Hence, columns like ID and Profile name can be removed.\n",
        "\n",
        "The removal of missing values from the data collection is another crucial step. For example, we have empty reviews in this data collection, which can be eliminated.\n",
        "\n",
        "Besides, deleting incorrect data is an essential, because some of the reviews have only special characters and dates in the column Summary, which are not helpful.\n",
        "\n",
        "Data cleaning is a necessary step before feeding a dataset to a machine learning model, as passing a dataset with garbage results in garbage output.\n",
        "\n",
        "Strategy to clean data includes: \n",
        "\n",
        "locate missing data- The 'isnull' function, which is actually a common function, helps us discover missing values in our dataset. The output is a list of boolean values.\n",
        "For example, if the data points Summary and Text have missing values, then these columns are marked TRUE.\n",
        "From here, you can drop the data (the dropna() function is used) or\n",
        "you can input the data (the fillna() function is used) based on the other values in the dataset or give it as a No Review.\n",
        "\n",
        "Normalize Casing- To avoid confusing our algorithms, we'll convert all of our reviews to lowercase(.str.lower() is used).\n",
        "Because it's possible that it'll be overlooked while deleting duplicates.\n",
        "\n",
        "Drop duplicates- The drop duplicates function, which has the parameters subset,keep, and inplace, can be used to pick unique rows.\n",
        "\n",
        "Handling Outliers- The Z-score is a measure of how far a value is from the mean, and it will be used to remove outliers from a single column.\n",
        "Values that are far from the mean are typically outliers\n",
        "\n",
        "Handling Bad Values- The values that either don’t make sense or that have an unexpected type. For example having only specaial characters or dates in Review Text.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LdRrRPPZ0Mn"
      },
      "source": [
        "Question 4 (20 points). Data cleaning: There are two datasets TwADR-L (from Twitter) and AskAPatient (Link: https://zenodo.org/record/55013#.YgU2NN-ZO4T) for medical concept\n",
        "normalization. However, the two datasets have serious data quality problems. Please read the introduction of the datasets and clean the two datasets by following the steps in the statement.\n",
        "\n",
        "In the original dataset, the TwADR-L had 48,057 training, 1,256 validation and 1,427 test examples. The test set (all\n",
        "test samples from 10 folds combined) consists of 765 unique phrases and 273 unique classes (medical concepts). The AskAPatient dataset contained 156,652 training, 7,926 validation, and 8,662 test examples. The entire test set (all test samples\n",
        "from 10 folds combined) consists of 3,749 unique phrases and 1,035 unique classes (medical concepts). The authors\n",
        "randomly split each dataset into ten equal folds, ran 10-fold cross validation and reported the accuracy averaged across the\n",
        "ten folds. \n",
        "\n",
        "We found that, in the original data set, many phrase-label pairs appeared multiple times within the same training data file\n",
        "and also across the training and test data sets in the same fold. In the AskAPatient data set, on average 35.82% of the test data overlapped with training data in the same fold. In the Twitter (TwADR-L) dataset, on average 8.62% of the test set had an overlap with the training data in the same fold. Having a large overlap between the training and the test data can potentially\n",
        "introduce bias in the model and contribute to high accuracy. It is not unlikely that the high model performance reported in the original paper may be triggered by the the large overlap between the training and test sets.\n",
        "\n",
        "Therefore to remove the bias, we further cleaned and recreated the training, validation, and test sets such that each\n",
        "phrase-label pair appears only once in the entire dataset (either in training, validation or test set).\n",
        "\n",
        "(1) First, we combined all examples in training, validation and test data from the original data set and then removed all\n",
        "duplicate phrase-label pairs (examples that have the same phrase and label pair and appear more than once in training/validation/test datasets). Table II shows the statistics of the new dataset (after removing duplicates). The Twitter data set had 3,157 unique phrase-label pairs and 2,220 unique labels (medical concepts) while 173 phrases had multiple labels (i.e., they were assigned to more than one label). Many concepts had only one example, and the concept that had the most number\n",
        "of examples had 36 phrases. On average, each concept had 1.42 examples. The AskAPatient data set had 4,496 unique phrase-label pairs, 1,036 unique labels while 26 phrases had multiple labels. Table III shows examples of phrases that had multiple labels. For example, ‘mad’ can be mapped to ‘anger’ or ‘rage’ and ‘sore’ can be mapped to ‘pain’ or ‘myalgia’.\n",
        "\n",
        "(2) Second, we remove all concepts that had less than five examples. The statistics of the final data are shown in Table IV.\n",
        "\n",
        "(3) Third, we divide all examples without multiple labels into random 10 folds such that each unique phrase-label pair\n",
        "appears once in one of the 10 test sets. We add the pairs with multiple labels into the training data. This final 10-folds\n",
        "dataset is used in all our experiments.\n",
        "\n",
        "(The original paper can be download on canvas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CoWhKCPZ0Mo"
      },
      "outputs": [],
      "source": [
        "#importing pandas Library\n",
        "import pandas as pd\n",
        "\n",
        "#Method to read the test,train and validation files from github for both the datasets\n",
        "def generateDataFrame(inputDataSet:str,inputFile:str)->pd.DataFrame:\n",
        "  df=pd.DataFrame(); \n",
        "\n",
        "  for index in range(10): #Taking range 10 to read 10 files for each type(test,train and validation)\n",
        "    url='https://raw.githubusercontent.com/gantaphani/Phanesh_INFO5502_Spring2022/main/'+inputDataSet+'/'+inputFile.capitalize()+'/'+inputDataSet+'.fold-'+str(index)+'.'+inputFile+'.txt'\n",
        "    temp=pd.read_csv(url,sep='\\t',encoding = 'unicode_escape',header=None) #reading from text file\n",
        "    df=df.append(temp)\n",
        "  return df\n",
        "\n",
        "#Method to write the test,train files for both the datasets\n",
        "def createFinalFolds(df,dataSet,file):\n",
        "    noOfRows=int(len(df)/10)\n",
        "\n",
        "    for i in range(10): #Taking range 10 to generate 10 folds\n",
        "      if i==9: #if the file is last one then we will write all the remaining rows into the file\n",
        "        temp=df\n",
        "      else:\n",
        "        temp=df.sample(n = noOfRows) #randomly selecting 10% of rows from the dataframe to store in each fold\n",
        "\n",
        "      temp[['ID','LABEL','PHRASE']].to_csv(''+dataSet+'.fold-'+str(i)+'.'+file+'.txt',sep='\\t',index=False,header=False) #writing to text file\n",
        "      df.drop(temp.index,inplace=True)\n",
        "\n",
        "def output():\n",
        "  TwADRLDataSet=pd.DataFrame();\n",
        "  askAPatientDataSet=pd.DataFrame();\n",
        "\n",
        "  Table2List=list()\n",
        "  Table4List=list()\n",
        "\n",
        "  files=['test','train','validation'] #3 types of file types\n",
        "  dataSets=['TwADR-L','AskAPatient'] #2 types of datasets\n",
        "\n",
        "  for dataset in dataSets: #looping over datsets\n",
        "    for file in files: #looping over file types\n",
        "      if dataset=='TwADR-L':\n",
        "          TwADRLDataSet=TwADRLDataSet.append(generateDataFrame(dataset,file),ignore_index=True) #storing all the contents of 'TwADR-L' dataset into the dataframe(TwADRLDataSet)\n",
        "      elif dataset=='AskAPatient':\n",
        "        askAPatientDataSet=askAPatientDataSet.append(generateDataFrame(dataset,file),ignore_index=True) #storing all the contents of 'AskAPatient' dataset into the dataframe(askAPatientDataSet)\n",
        "\n",
        "\n",
        "  headers=['ID','LABEL','PHRASE']#column names\n",
        "\n",
        "  #giving header names and strip/upper the values for the dataframe 'TwADRLDataSet'\n",
        "  TwADRLDataSet.columns=headers\n",
        "  TwADRLDataSet['LABEL']=TwADRLDataSet['LABEL'].str.strip(' ').str.upper()\n",
        "  TwADRLDataSet['PHRASE']=TwADRLDataSet['PHRASE'].str.strip(' ').str.upper()\n",
        "\n",
        "  #giving header names and strip/upper the values for the dataframe 'askAPatientDataSet'\n",
        "  askAPatientDataSet.columns=headers\n",
        "  askAPatientDataSet['LABEL']=askAPatientDataSet['LABEL'].str.strip(' ').str.upper()\n",
        "  askAPatientDataSet['PHRASE']=askAPatientDataSet['PHRASE'].str.strip(' ').str.upper()\n",
        "\n",
        "  #removing duplicate rows/NULL values from both the data frames\n",
        "  askAPatientDataSet.drop_duplicates(subset=['LABEL','PHRASE'],keep=\"first\",inplace=True)\n",
        "  askAPatientDataSet.dropna(inplace=True)\n",
        "  TwADRLDataSet.drop_duplicates(subset=['LABEL','PHRASE'],keep=\"first\",inplace=True)\n",
        "  TwADRLDataSet.dropna(inplace=True)\n",
        "  \n",
        "  #Obtaining result for Table II\n",
        "  Table2List.append(['# unique phrases',len(TwADRLDataSet['PHRASE'].unique()),len(askAPatientDataSet['PHRASE'].unique())])\n",
        "  Table2List.append(['# unique labels',len(TwADRLDataSet['LABEL'].unique()),len(askAPatientDataSet['LABEL'].unique())])\n",
        "  Table2List.append(['# unique phrase-label pairs',len(TwADRLDataSet),len(askAPatientDataSet)])\n",
        "  Table2List.append(['# phrases with multiple labels',len(pd.DataFrame(TwADRLDataSet.groupby(['PHRASE']).LABEL.count()).loc[pd.DataFrame(TwADRLDataSet.groupby(['PHRASE']).LABEL.count())['LABEL']>1]),len(pd.DataFrame(askAPatientDataSet.groupby(['PHRASE']).LABEL.count()).loc[pd.DataFrame(askAPatientDataSet.groupby(['PHRASE']).LABEL.count())['LABEL']>1])])\n",
        "  Table2List.append(['Min # examples per label',pd.DataFrame(TwADRLDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].min(),pd.DataFrame(askAPatientDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].min()])\n",
        "  Table2List.append(['Max # examples per label',pd.DataFrame(TwADRLDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].max(),pd.DataFrame(askAPatientDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].max()])\n",
        "  Table2List.append(['Avg # examples per label',str(round(pd.DataFrame(TwADRLDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].mean(),2)),str(round(pd.DataFrame(askAPatientDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].mean(),2))])\n",
        "  Table2DataSet=pd.DataFrame(Table2List,columns=['','TwADR-L','AskAPatient'])\n",
        "\n",
        "  print('###DATA STATISTICS AFTER REMOVING DUPLICATES FROM COMBINED TRAINING, VALIDATION, AND TEST DATA###')\n",
        "  print(Table2DataSet.to_string(index=False))\n",
        "  \n",
        "  #Calculating and storing the count of examples associated to each medical concept for both the datasets\n",
        "  TwADRLDataSet['PHRASE COUNTS']=TwADRLDataSet.groupby(['LABEL'])['PHRASE'].transform('count')\n",
        "  askAPatientDataSet['PHRASE COUNTS']=askAPatientDataSet.groupby(['LABEL'])['PHRASE'].transform('count')\n",
        "\n",
        "  #Deleting the medical concepts that had less than five examples\n",
        "  TwADRLDataSet.drop(TwADRLDataSet.loc[TwADRLDataSet['PHRASE COUNTS']<5].index,inplace=True)\n",
        "  askAPatientDataSet.drop(askAPatientDataSet.loc[askAPatientDataSet['PHRASE COUNTS']<5].index,inplace=True)\n",
        "\n",
        "  #Calculating and storing the count of medical concepts associated to each phrase for both the datasets\n",
        "  TwADRLDataSet['LABEL COUNTS']=TwADRLDataSet.groupby(['PHRASE'])['LABEL'].transform('count')\n",
        "  askAPatientDataSet['LABEL COUNTS']=askAPatientDataSet.groupby(['PHRASE'])['LABEL'].transform('count')\n",
        "\n",
        "  #storing the Phrase that has no multiple labels in Test Dataset \n",
        "  TwADRLTestDataset=TwADRLDataSet.loc[TwADRLDataSet['LABEL COUNTS']==1].copy()\n",
        "  askAPatientTestDataset=askAPatientDataSet.loc[askAPatientDataSet['LABEL COUNTS']==1].copy()\n",
        "\n",
        "  #storing the Phrase that has multiple labels in Training Dataset \n",
        "  TwADRLTrainingDataset=TwADRLDataSet.loc[TwADRLDataSet['LABEL COUNTS']>1].copy()\n",
        "  askAPatientTrainingDataset=askAPatientDataSet.loc[askAPatientDataSet['LABEL COUNTS']>1].copy()\n",
        "\n",
        "  #Obtaining result for Table III\n",
        "  print(\"\\n\")\n",
        "  print('###EXAMPLES OF PHRASES WITH MULTIPLE LABELS FOR TwADR-L###')\n",
        "  print(TwADRLTrainingDataset.groupby('PHRASE').agg(lambda x : ','.join(x))['LABEL'].head(10))\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print('###EXAMPLES OF PHRASES WITH MULTIPLE LABELS FOR AskAPatient###')\n",
        "  print(askAPatientTrainingDataset.groupby('PHRASE').agg(lambda x : ','.join(x))['LABEL'].head(10))\n",
        "\n",
        "  #Obtaining result for Table IV\n",
        "  Table4List.append(['# unique phrases',len(TwADRLDataSet['PHRASE'].unique()),len(askAPatientDataSet['PHRASE'].unique())])\n",
        "  Table4List.append(['# unique labels',len(TwADRLDataSet['LABEL'].unique()),len(askAPatientDataSet['LABEL'].unique())])\n",
        "  Table4List.append(['# unique phrase-label pairs',len(TwADRLDataSet),len(askAPatientDataSet)])\n",
        "  Table4List.append(['# phrases with multiple labels',len(pd.DataFrame(TwADRLDataSet.groupby(['PHRASE']).LABEL.count()).loc[pd.DataFrame(TwADRLDataSet.groupby(['PHRASE']).LABEL.count())['LABEL']>1]),len(pd.DataFrame(askAPatientDataSet.groupby(['PHRASE']).LABEL.count()).loc[pd.DataFrame(askAPatientDataSet.groupby(['PHRASE']).LABEL.count())['LABEL']>1])])\n",
        "  Table4List.append(['Min # examples per label',pd.DataFrame(TwADRLDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].min(),pd.DataFrame(askAPatientDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].min()])\n",
        "  Table4List.append(['Max # examples per label',pd.DataFrame(TwADRLDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].max(),pd.DataFrame(askAPatientDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].max()])\n",
        "  Table4List.append(['Avg # examples per label',str(round(pd.DataFrame(TwADRLDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].mean(),2)),str(round(pd.DataFrame(askAPatientDataSet.groupby(['LABEL']).PHRASE.count())['PHRASE'].mean(),2))])\n",
        "  Table4DataSet=pd.DataFrame(Table4List,columns=['','TwADR-L','AskAPatient'])\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print('###DATA STATISTICS AFTER REMOVING CONCEPTS THAT HAVE LESS THAN FIVE EXAMPLES###')\n",
        "  print(Table4DataSet.to_string(index=False))\n",
        "  \n",
        "  #writing the final data to 10 text folds\n",
        "  createFinalFolds(TwADRLTestDataset,'TwADR-L','test')\n",
        "  createFinalFolds(TwADRLTrainingDataset,'TwADR-L','train')\n",
        "  createFinalFolds(askAPatientTestDataset,'AskAPatient','test')\n",
        "  createFinalFolds(askAPatientTrainingDataset,'AskAPatient','train')\n",
        "  \n",
        "output()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "lab_assignment_03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
