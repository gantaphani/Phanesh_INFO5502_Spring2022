{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gantaphani/Phanesh_INFO5502_Spring2022/blob/main/lab_assignment_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxEpTeQLjb_s"
      },
      "source": [
        "## The sixth Lab-assignment (03/24/2022, 50 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXndqsZ9jb_w"
      },
      "source": [
        "The purpose of this exercise is to build a simple predicition model which can helpyou understand the workflow of machine learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSUNHXl5jb_x"
      },
      "source": [
        "### Task Decription "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAX-eLawjb_x"
      },
      "source": [
        "The goal of this assignment is to predict bike share use, given the hour, day, and information about the weather. Companies like Divvy try to predict how much demand there will be for bikes on any given day to allocate resources to redistribute bikes so that, ideally, very few bike stations are ever full (when you can’t park your bike) or empty (when you can’t pick up a bike if you want to).\n",
        "\n",
        "The data (link: https://github.com/unt-iialab/info5502-spring2022/tree/main/datasets/lab_assignment_06) in Github provides detailed information on the data set and necessary downloads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdezl7n7jb_y"
      },
      "source": [
        "### Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbL02v_ljb_y"
      },
      "source": [
        "You are provided hourly rental data spanning two years (link: https://github.com/unt-iialab/info5502-spring2022/tree/main/datasets/lab_assignment_06). For this task, the training set is comprised of the first 16 days of each month, while the test set is the 17-19th day of the month. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period. That is, predict \"count\" without using \"count\" or its components \"casual\" and \"registered\".\n",
        "\n",
        "Data Fields\n",
        "\n",
        "datetime - hourly date + timestamp\n",
        "\n",
        "season - 1 = spring, 2 = summer, 3 = fall, 4 = winter\n",
        "\n",
        "holiday - whether the day is considered a holiday\n",
        "\n",
        "workingday - whether the day is neither a weekend nor holiday\n",
        "\n",
        "weather -\n",
        "\n",
        "1 - Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "\n",
        "2 - Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "\n",
        "3 - Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "\n",
        "4 - Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
        "\n",
        "temp - temperature in Celsius\n",
        "\n",
        "atemp - \"feels like\" temperature in Celsius\n",
        "\n",
        "humidity - relative humidity\n",
        "\n",
        "windspeed - wind speed\n",
        "\n",
        "casual - number of non-registered user rentals initiated\n",
        "\n",
        "registered - number of registered user rentals initiated\n",
        "\n",
        "count - number of total rentals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-jk8Lq3jb_z"
      },
      "source": [
        "### Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OprErCIFjb_z"
      },
      "source": [
        "Submission Format\n",
        "\n",
        "Your output (a separate file) must have a header line and should be structured in the following format:\n",
        "\n",
        " datetime,count\n",
        " \n",
        " 2011-01-20 00:00:00,0 \n",
        " \n",
        " 2011-01-20 01:00:00,0\n",
        " \n",
        " 2011-01-20 02:00:00,0\n",
        " \n",
        " ...\n",
        " \n",
        "The tutorial code should demonstrate how to generate such a file from a very simple prediction model. Note, these prediction are to be done on the test file under the data tab, where you do not know the actual count, and should match the rows of the test file in count and order.\n",
        "\n",
        "Your predictions should be compared to the ground truth information (sample_prediction.csv). Score are calculated using Root Mean Squared Error (RMSE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX4jF9IMjb_0"
      },
      "source": [
        "### Tips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV4yHdLcjb_0"
      },
      "source": [
        "●\tAdd features: Pick columns/features from the data you already have. Or make a new feature from the ones you have. For example, the tutorial makes ‘hour’ from the datetime stamp, which seemed very useful. How about ‘month’?\n",
        "\n",
        "●\tModel selection: Try different models. Make sure they are regression models rather than classification models. Tip: random forest regression is a good, all around modeling strategy on complicated data sets.\n",
        "\n",
        "●\tModel tuning: Almost all regression models have parameters to tune (“hyperparameters”). E.g. polynomial regression has the degree of the polynomial (n = 1 for a line, n=2 for a quadratic fit, n=3 for a cubic fit…). Generally, one extreme makes the model too simple (e.g. a line for a curved set of points) and the other extreme makes the model overfit/be too complex, and usually the right choice is in between. For some models it is obvious what to tune (e.g. k for k nearest neighbors regression) and some don’t need much tuning with defaults that often work well. e.g. try changing the number of trees used in the random forest model!\n",
        "\n",
        "●\tCross validation: The tutorial has a simple way of separating training and test data, however, there are better ways of splitting training and test data. Look into cross validation techniques, which are more reliable than an arbitrary split of training and test data.\n",
        "\n",
        "●\tSeparate models for ...: Notice that count comes from just adding casual riders and registered riders. However, what if these two types of riders acted very differently? It might make sense to make two separate models and just add the results of both models together. This is also true for any subsets of your data that may behave wildly differently (e.g. create a separate model for each season?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J45sqE_5jb_1"
      },
      "source": [
        "### Your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "wO-mt5l3jb_2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading/printing traning and test datasets\n",
        "trainingSet=pd.read_csv('https://raw.githubusercontent.com/unt-iialab/info5502-spring2022/main/datasets/lab_assignment_06/train_luc.csv',sep=',')\n",
        "print(str(\"!!!TRAINING SET!!!\").center(100))\n",
        "print(trainingSet.head(5).to_string())\n",
        "testSet=pd.read_csv('https://raw.githubusercontent.com/unt-iialab/info5502-spring2022/main/datasets/lab_assignment_06/test_luc.csv',sep=',')\n",
        "print(str(\"!!!TESTING SET!!!\").center(100))\n",
        "print(testSet.head(5).to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsosiqVCourG",
        "outputId": "7ea8e594-a3bf-411c-ee5b-99bf79420612"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         !!!TRAINING SET!!!                                         \n",
            "              datetime  season  holiday  workingday  weather  temp   atemp  humidity  windspeed  casual  registered  count\n",
            "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395        81        0.0       3          13     16\n",
            "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635        80        0.0       8          32     40\n",
            "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635        80        0.0       5          27     32\n",
            "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395        75        0.0       3          10     13\n",
            "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395        75        0.0       0           1      1\n",
            "                                         !!!TESTING SET!!!                                          \n",
            "              datetime  season  holiday  workingday  weather  temp  atemp  humidity  windspeed\n",
            "0  2011-01-17 00:00:00       1        1           0        2  8.20  9.850        47    15.0013\n",
            "1  2011-01-17 01:00:00       1        1           0        2  8.20  9.850        44    12.9980\n",
            "2  2011-01-17 02:00:00       1        1           0        2  7.38  8.335        43    16.9979\n",
            "3  2011-01-17 03:00:00       1        1           0        2  7.38  9.090        43    12.9980\n",
            "4  2011-01-17 04:00:00       1        1           0        2  7.38  9.850        43     8.9981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking For Null Values in both the datasets\n",
        "print(trainingSet.any().isna())\n",
        "print('Note there are no null values in the Traning Dataset\\n')\n",
        "print(testSet.any().isna())\n",
        "print('Note there are no null values in the Testing Dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfUXbM1Po5Sy",
        "outputId": "2943ce6a-cba9-4c2c-a05a-6b5dc2033c4d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datetime      False\n",
            "season        False\n",
            "holiday       False\n",
            "workingday    False\n",
            "weather       False\n",
            "temp          False\n",
            "atemp         False\n",
            "humidity      False\n",
            "windspeed     False\n",
            "casual        False\n",
            "registered    False\n",
            "count         False\n",
            "dtype: bool\n",
            "Note there are no null values in the Traning Dataset\n",
            "\n",
            "datetime      False\n",
            "season        False\n",
            "holiday       False\n",
            "workingday    False\n",
            "weather       False\n",
            "temp          False\n",
            "atemp         False\n",
            "humidity      False\n",
            "windspeed     False\n",
            "dtype: bool\n",
            "Note there are no null values in the Testing Dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking For Duplicate values in both the datasets\n",
        "print(trainingSet[trainingSet.duplicated()])\n",
        "print('Note there are no Duplicates in the Traning Dataset\\n')\n",
        "print(testSet[testSet.duplicated()])\n",
        "print('Note there are no Duplicates in the Testing Dataset\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8MwQmYim-H1",
        "outputId": "f85f2b71-7b99-4bef-9f06-0fdef7fea7ce"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [datetime, season, holiday, workingday, weather, temp, atemp, humidity, windspeed, casual, registered, count]\n",
            "Index: []\n",
            "Note there are no Duplicates in the Traning Dataset\n",
            "\n",
            "Empty DataFrame\n",
            "Columns: [datetime, season, holiday, workingday, weather, temp, atemp, humidity, windspeed]\n",
            "Index: []\n",
            "Note there are no Duplicates in the Testing Dataset\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding new column Hour to both the datasets\n",
        "trainingSet['hour']=trainingSet['datetime'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S').time().hour)\n",
        "print(str(\"!!!UPDATED TRAINING SET!!!\").center(100))\n",
        "print(trainingSet.head(5).to_string())\n",
        "testSet['hour']=testSet['datetime'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S').time().hour)\n",
        "print(str(\"!!!UPDATED TESTING SET!!!\").center(100))\n",
        "print(testSet.head(5).to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zL7aRMqCS7I",
        "outputId": "a9a9003d-3b8f-4386-bdbb-10feb0fab2c5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     !!!UPDATED TRAINING SET!!!                                     \n",
            "              datetime  season  holiday  workingday  weather  temp   atemp  humidity  windspeed  casual  registered  count  hour\n",
            "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395        81        0.0       3          13     16     0\n",
            "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635        80        0.0       8          32     40     1\n",
            "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635        80        0.0       5          27     32     2\n",
            "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395        75        0.0       3          10     13     3\n",
            "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395        75        0.0       0           1      1     4\n",
            "                                     !!!UPDATED TESTING SET!!!                                      \n",
            "              datetime  season  holiday  workingday  weather  temp  atemp  humidity  windspeed  hour\n",
            "0  2011-01-17 00:00:00       1        1           0        2  8.20  9.850        47    15.0013     0\n",
            "1  2011-01-17 01:00:00       1        1           0        2  8.20  9.850        44    12.9980     1\n",
            "2  2011-01-17 02:00:00       1        1           0        2  7.38  8.335        43    16.9979     2\n",
            "3  2011-01-17 03:00:00       1        1           0        2  7.38  9.090        43    12.9980     3\n",
            "4  2011-01-17 04:00:00       1        1           0        2  7.38  9.850        43     8.9981     4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Taking all columns as features for higher accuracy, except the target ones to predict count of Bikers\n",
        "Features=trainingSet[['hour','season','holiday','workingday','weather','temp','atemp','humidity','windspeed']]\n",
        "Targets=trainingSet['casual']"
      ],
      "metadata": {
        "id": "yBolNKLZocWc"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataset into training and test sets\n",
        "TrainFeatures,TestFeatures,TrainTargets,TestTargets=train_test_split(Features,Targets,test_size = 0.25, random_state = 42)\n",
        "print(\"Training Features Shape\",TrainFeatures.shape)\n",
        "print(\"Training Targets Shape\",TrainTargets.shape)\n",
        "print(\"Testing Features Shape\",TestFeatures.shape)\n",
        "print(\"Testing Targets Shape\",TestTargets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA-GM-yWsN_9",
        "outputId": "f6c903c6-8088-4f85-b645-746f61d9cfb0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features Shape (6880, 9)\n",
            "Training Targets Shape (6880,)\n",
            "Testing Features Shape (2294, 9)\n",
            "Testing Targets Shape (2294,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building and Training the Random Forest Regression Model\n",
        "rf=RandomForestRegressor(n_estimators=1000,random_state=42)\n",
        "rf.fit(TrainFeatures,TrainTargets)\n",
        "#Predicting on the Test Set and calcualting root mean squared error\n",
        "forestPredictedValues=rf.predict(TestFeatures)\n",
        "RMSE=math.sqrt(np.square(np.subtract(forestPredictedValues,TestTargets)).mean())\n",
        "print(RMSE)"
      ],
      "metadata": {
        "id": "HrvhiyAetKWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad1abe6-5063-4ed6-a5cf-dadd8e78bdd8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.11069071953916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building and Training the Decision Tree Regression Model\n",
        "dt=DecisionTreeRegressor()\n",
        "dt.fit(TrainFeatures,TrainTargets)\n",
        "#Predicting on the Test Set and calcualting root mean squared error\n",
        "decisionPredictedValues=dt.predict(TestFeatures)\n",
        "RMSE=math.sqrt(np.square(np.subtract(decisionPredictedValues,TestTargets)).mean())\n",
        "print(RMSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvNFrVVktT1Y",
        "outputId": "89a67fc2-04ea-4976-8b49-b165233d97cc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.02168414434478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building and Training the Linear Regression Model\n",
        "lr=LinearRegression()\n",
        "lr.fit(TrainFeatures,TrainTargets)\n",
        "#Predicting on the Test Set and calcualting root mean squared error\n",
        "linearPredictedValues=lr.predict(TestFeatures)\n",
        "RMSE=math.sqrt(np.square(np.subtract(linearPredictedValues,TestTargets)).mean())\n",
        "print(RMSE)"
      ],
      "metadata": {
        "id": "9aKaDlrB4_GB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc92fec-640c-4c77-f9ba-31adb0a729a8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.91938778272201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building and Training the K Neighbors Regression Model\n",
        "kn=KNeighborsRegressor(n_neighbors=5)\n",
        "kn.fit(TrainFeatures,TrainTargets)\n",
        "#Predicting on the Test Set and calcualting root mean squared error\n",
        "kneighbourPredictedValues=kn.predict(TestFeatures)\n",
        "RMSE=math.sqrt(np.square(np.subtract(kneighbourPredictedValues,TestTargets)).mean())\n",
        "print(RMSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OtDMftS0vXW",
        "outputId": "d24a677a-ac03-440b-ebae-ac2a9c13694d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.476138596420824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can see that RMS error for Random Forest,Decision Tree Regression Models is less,when compared to other models. So this models will be used for better prediction results.\n",
        "#we will use Random Forest Regression Model to predict the count of Casual Users\n",
        "#we will predict for actual Testing set,i.e for 17-19th of each month\n",
        "rf.fit(trainingSet[['hour','season','holiday','workingday','weather','temp','atemp','humidity','windspeed']],trainingSet['casual'])\n",
        "PredictedValues=rf.predict(testSet[['hour','season','holiday','workingday','weather','temp','atemp','humidity','windspeed']])\n",
        "testSet['casual']=np.round(PredictedValues,2)"
      ],
      "metadata": {
        "id": "pAtnepC_03Z3"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we will use Decision Tree Regression Model to predict the count of Registered Users\n",
        "dt.fit(trainingSet[['hour','season','holiday','workingday','weather','temp','atemp','humidity','windspeed']],trainingSet['registered'])\n",
        "PredictedValues=dt.predict(testSet[['hour','season','holiday','workingday','weather','temp','atemp','humidity','windspeed']])\n",
        "testSet['registered']=np.round(PredictedValues,2)"
      ],
      "metadata": {
        "id": "RdDLglGw07G9"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding both the counts of casual and registered users to get totals\n",
        "testSet['count']=testSet['casual']+testSet['registered']\n",
        "testSet[['datetime','count']].to_csv('my_prediction.csv',header=True,sep=',',index=False,encoding='utf-8')"
      ],
      "metadata": {
        "id": "p-5lvuKMHaaD"
      },
      "execution_count": 87,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "lab_assignment_06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}